{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/homerabbitsky/HelloAI/blob/main/Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qfZQ0fhPt-1",
        "outputId": "91872509-5d80-4f25-f05c-6e91084486ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "before converting... 5\n",
            "7\n",
            "after converting y... [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "6000/6000 [==============================] - 24s 4ms/step - loss: 0.3209 - accuracy: 0.9124 - val_loss: 0.1785 - val_accuracy: 0.9469\n",
            "Test loss: 0.17852474749088287\n",
            "Test accuracy: 0.9469000101089478\n"
          ]
        }
      ],
      "source": [
        "# based on https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.datasets.mnist as kdm\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# tf.config.set_visible_devices([], 'GPU') # if you have an m1/m2 mac, uncomment this line to run wayyyy faster if you have local install of jupyter. leave commented if you are running on google colab \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "print(\"before converting...\", y_train[0])\n",
        "\n",
        "# reshape\n",
        "img_rows, img_cols = 28, 28\n",
        "# normalize inputs to between 0 and 1\n",
        "import numpy as np\n",
        "x_train = np.true_divide(x_train, 255)\n",
        "x_test = np.true_divide(x_test, 255)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(y_test[0])\n",
        "\n",
        "# convert to vector outputs \n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "print(\"after converting y...\", y_test[0])\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  layers.Flatten(input_shape=(28,28)),\n",
        "  layers.Dense(100, activation='sigmoid'),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=10,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save(\"test_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcK4luC5Zzmi"
      },
      "outputs": [],
      "source": [
        "def findTroublesomeImageKERAS(model, x_test):\n",
        "  worsta = 1\n",
        "  worsti = 0\n",
        "  for i in range(len(x_test)):\n",
        "    prediction = model.predict(x_test[i], verbose=False)\n",
        "    max_a = np.max(prediction)\n",
        "    if max_a < worsta:\n",
        "      worsta = max_a\n",
        "      worsti = i\n",
        "  return (worsta, worsti)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvmAOO5OWTrG",
        "outputId": "1b5fdd4f-269b-42c8-f3fe-fa240b59bc56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.17852474749088287, 0.9469000101089478]\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "[[5.2142653e-08 9.9365425e-01 3.1559356e-04 7.7011500e-04 8.1778135e-06\n",
            "  4.2704612e-04 1.7263803e-04 1.3467764e-04 4.2456985e-03 2.7185015e-04]]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(0.23342237, 2770)\n"
          ]
        }
      ],
      "source": [
        "print(score)\n",
        "#print(x_test[768])\n",
        "a = model.predict(x_test[768:769])\n",
        "print(a)\n",
        "print(y_test[768])\n",
        "troublesome = findTroublesomeImageKERAS(model, x_test)\n",
        "print(troublesome)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "f6qi6EKSfEN5",
        "outputId": "e4f7181d-1ed4-4363-ac74-e4555bc5cbcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[2.1933114e-04 6.9563421e-03 7.1216943e-03 2.3342237e-01 2.2985999e-01\n",
            "  7.8104213e-02 2.0286709e-01 8.0640174e-02 1.5241440e-01 8.3944304e-03]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1553782790>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "a = model.predict(x_test[2770])\n",
        "print(a)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(x_test[2770], (28,28)),cmap=\"gray_r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuVsMZaqdqKK",
        "outputId": "2962c6b1-0558-47be-9ef6-6c6ef8997aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "def dec_to_binvector4(dec):\n",
        "  binstr = \"{0:04b}\".format(int(dec))\n",
        "  binvect = []\n",
        "  for b in binstr:\n",
        "    binvect.append(int(b))\n",
        "  return binvect\n",
        "\n",
        "# expects y_data to be a list of nonnegative integer numbers (e.g., 0, 1, 2, 3)\n",
        "# returns the binary representation of each y using the specified number of bits\n",
        "def to_binary(y_data):\n",
        "  return [np.array(dec_to_binvector4(y)).reshape(4, 1) for y in y_data]\n",
        "\n",
        "print(dec_to_binvector4(7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi76OiM6hyY2",
        "outputId": "98b02ba7-6e9d-40bd-bee9-66ab656f5481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 0.0637 - accuracy: 0.5743 - val_loss: 0.0278 - val_accuracy: 0.5879\n",
            "Epoch 2/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0225 - accuracy: 0.6191 - val_loss: 0.0194 - val_accuracy: 0.6273\n",
            "Epoch 3/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0157 - accuracy: 0.6431 - val_loss: 0.0152 - val_accuracy: 0.6367\n",
            "Epoch 4/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0123 - accuracy: 0.6503 - val_loss: 0.0144 - val_accuracy: 0.6504\n",
            "Epoch 5/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0101 - accuracy: 0.6630 - val_loss: 0.0130 - val_accuracy: 0.6331\n",
            "Epoch 6/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0086 - accuracy: 0.6757 - val_loss: 0.0127 - val_accuracy: 0.6753\n",
            "Epoch 7/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0074 - accuracy: 0.6817 - val_loss: 0.0117 - val_accuracy: 0.6883\n",
            "Epoch 8/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0063 - accuracy: 0.6841 - val_loss: 0.0118 - val_accuracy: 0.7145\n",
            "Epoch 9/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0057 - accuracy: 0.6927 - val_loss: 0.0129 - val_accuracy: 0.6613\n",
            "Epoch 10/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0049 - accuracy: 0.6930 - val_loss: 0.0121 - val_accuracy: 0.6385\n",
            "Epoch 11/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0045 - accuracy: 0.6887 - val_loss: 0.0113 - val_accuracy: 0.6768\n",
            "Epoch 12/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0041 - accuracy: 0.6887 - val_loss: 0.0113 - val_accuracy: 0.6768\n",
            "Epoch 13/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0037 - accuracy: 0.6816 - val_loss: 0.0116 - val_accuracy: 0.6607\n",
            "Epoch 14/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0033 - accuracy: 0.6866 - val_loss: 0.0115 - val_accuracy: 0.7075\n",
            "Epoch 15/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0031 - accuracy: 0.6851 - val_loss: 0.0112 - val_accuracy: 0.6637\n",
            "Epoch 16/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0029 - accuracy: 0.6725 - val_loss: 0.0112 - val_accuracy: 0.6602\n",
            "Epoch 17/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0027 - accuracy: 0.6786 - val_loss: 0.0115 - val_accuracy: 0.7012\n",
            "Epoch 18/30\n",
            "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0025 - accuracy: 0.6746 - val_loss: 0.0114 - val_accuracy: 0.6488\n",
            "Epoch 19/30\n",
            "6000/6000 [==============================] - 27s 4ms/step - loss: 0.0023 - accuracy: 0.6880 - val_loss: 0.0117 - val_accuracy: 0.7235\n",
            "Epoch 20/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0022 - accuracy: 0.6914 - val_loss: 0.0118 - val_accuracy: 0.6701\n",
            "Epoch 21/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0020 - accuracy: 0.6891 - val_loss: 0.0113 - val_accuracy: 0.7138\n",
            "Epoch 22/30\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 0.0019 - accuracy: 0.6782 - val_loss: 0.0118 - val_accuracy: 0.6779\n",
            "Epoch 23/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0019 - accuracy: 0.6661 - val_loss: 0.0120 - val_accuracy: 0.6733\n",
            "Epoch 24/30\n",
            "6000/6000 [==============================] - 21s 3ms/step - loss: 0.0018 - accuracy: 0.6698 - val_loss: 0.0119 - val_accuracy: 0.6646\n",
            "Epoch 25/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0017 - accuracy: 0.6649 - val_loss: 0.0117 - val_accuracy: 0.6706\n",
            "Epoch 26/30\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 0.0016 - accuracy: 0.6656 - val_loss: 0.0116 - val_accuracy: 0.6790\n",
            "Epoch 27/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0015 - accuracy: 0.6721 - val_loss: 0.0128 - val_accuracy: 0.6704\n",
            "Epoch 28/30\n",
            "6000/6000 [==============================] - 21s 4ms/step - loss: 0.0015 - accuracy: 0.6704 - val_loss: 0.0112 - val_accuracy: 0.6599\n",
            "Epoch 29/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0015 - accuracy: 0.6733 - val_loss: 0.0113 - val_accuracy: 0.6769\n",
            "Epoch 30/30\n",
            "6000/6000 [==============================] - 26s 4ms/step - loss: 0.0014 - accuracy: 0.6709 - val_loss: 0.0121 - val_accuracy: 0.6533\n",
            "Test loss: 0.012079683132469654\n",
            "Test accuracy: 0.6532999873161316\n"
          ]
        }
      ],
      "source": [
        "# based on https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.datasets.mnist as kdm\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
        "\n",
        "\n",
        "# reshape\n",
        "img_rows, img_cols = 28, 28\n",
        "# normalize inputs to between 0 and 1\n",
        "import numpy as np\n",
        "x_train = np.true_divide(x_train, 255)\n",
        "x_test = np.true_divide(x_test, 255)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# convert to vector outputs \n",
        "num_classes = 10\n",
        "y_train = to_binary(y_train)\n",
        "y_test = to_binary(y_test)\n",
        "\n",
        "y_train = np.array(y_train).reshape(60000, 4)\n",
        "y_test = np.array(y_test).reshape(10000, 4)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  layers.Flatten(input_shape=(28,28)),\n",
        "  layers.Dense(100, activation='sigmoid'),\n",
        "  layers.Dense(10, activation='sigmoid'),\n",
        "  layers.Dense(4, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=10,\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save(\"test_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}